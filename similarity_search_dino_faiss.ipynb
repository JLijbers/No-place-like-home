{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7_RDVBETb2y"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WXMGRFGTb21"
      },
      "source": [
        "\n",
        "\n",
        "# Similarity search on Satellite Images (DINOv2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhLWfJaBTb23"
      },
      "source": [
        "## Install and import"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start by installing `faiss-gpu` which is a library for efficient similarity search and clustering of dense vectors.\n",
        "It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM.\n"
      ],
      "metadata": {
        "id": "kTOef62PweMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-gpu"
      ],
      "metadata": {
        "id": "rOPPCyqLV7Zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fNJkauOETb24"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoProcessor, AutoImageProcessor, AutoModel\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "import os\n",
        "import json\n",
        "import faiss\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLxsOGNjTb26"
      },
      "source": [
        "## Set-up folders"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we mount Google Drive and set up base paths for our images and data.\n"
      ],
      "metadata": {
        "id": "-CrpD_2owsh0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hpiFxq0Tb28"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Root folder in Google Drive\n",
        "DRIVE_BASE_PATH = '/content/drive/MyDrive/'"
      ],
      "metadata": {
        "id": "VF22NoPCWha1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set input folder\n",
        "IMAGES = os.path.join(DRIVE_BASE_PATH, 'dino', 'input_images')"
      ],
      "metadata": {
        "id": "jdb3VAlWWmu-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set 'home' image to search (replace with your search-file)\n",
        "HOME_IMAGE = os.path.join(DRIVE_BASE_PATH, 'dino', 'home.jpg')"
      ],
      "metadata": {
        "id": "yKNdOJsl1Uib"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK_oQGwhTb28"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions to use in the process:\n",
        "\n",
        "*   'extract_features' extracts image features using the DINOv2 model;\n",
        "*    'normalizeL2' normalizes the embeddings in L2 space."
      ],
      "metadata": {
        "id": "yxrpGJzCxLZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(image):\n",
        "    with torch.no_grad():\n",
        "        inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
        "        outputs = model(**inputs)\n",
        "        image_features = outputs.last_hidden_state\n",
        "        return image_features.mean(dim=1)"
      ],
      "metadata": {
        "id": "WKwzWxEObvzP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalizeL2(embeddings):\n",
        "    vector = embeddings.detach().cpu().numpy()\n",
        "    vector = np.float32(vector)\n",
        "    faiss.normalize_L2(vector)\n",
        "    return vector"
      ],
      "metadata": {
        "id": "T9uBs0xO15cv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load model and processor"
      ],
      "metadata": {
        "id": "vEz77pyt-f7O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use the 'base' DINOv2 model. It has 86 million parameters, a size of 331MB and the features extracted from an image have a dimensionality of 768."
      ],
      "metadata": {
        "id": "h5AaarWRdIvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
        "processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')\n",
        "model = AutoModel.from_pretrained('facebook/dinov2-base').to(device)"
      ],
      "metadata": {
        "id": "mdlZHsIqWBkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "0RLrvKllY6SV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Populate the images variable with all the images in the dataset folder\n",
        "images = [os.path.join(IMAGES, file_name) for file_name in os.listdir(IMAGES)]"
      ],
      "metadata": {
        "id": "TT3H0a1a8G9b"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create FAISS-index"
      ],
      "metadata": {
        "id": "RYsNE_4CcJtj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we create and populate a FAISS index for efficient similarity search.\n",
        "\n",
        "We choose IndexFlatL2 to measure the L2 (or Euclidean) distance between all given points between our query vector, and the vectors loaded into the index (the features extracted from the image dataset)."
      ],
      "metadata": {
        "id": "fQ-JPDmTxj0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def open_and_convert_image(image_path):\n",
        "    img = Image.open(image_path)\n",
        "    if img.mode != 'RGB':\n",
        "        img = img.convert('RGB')\n",
        "    return img"
      ],
      "metadata": {
        "id": "Z6StMY8l9y0O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use dimensionality of DINOv2 Base-model\n",
        "index = faiss.IndexFlatL2(768)\n",
        "\n",
        "#Iterate over the dataset to extract features and store features in index\n",
        "for image_path in tqdm(images):\n",
        "    img = open_and_convert_image(image_path)\n",
        "    vector = extract_features(img)\n",
        "    normalized_vector = normalizeL2(vector)\n",
        "    index.add(normalized_vector)\n",
        "\n",
        "#store the index\n",
        "faiss.write_index(index,\"dino.index\")"
      ],
      "metadata": {
        "id": "7mpWV3BHbPOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Similarity search"
      ],
      "metadata": {
        "id": "mLOKsMnA1PYi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We perform a similarity search using a reference image. The script retrieves the top 5 similar images from our dataset."
      ],
      "metadata": {
        "id": "Yj6W-bQ4xoxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Input image\n",
        "image = Image.open(HOME_IMAGE)\n",
        "\n",
        "#Extract features from home image\n",
        "image_features = extract_features(image)\n",
        "image_features = normalizeL2(image_features)\n",
        "\n",
        "#Search the top 5 images\n",
        "index = faiss.read_index(\"dino.index\")\n",
        "\n",
        "#Get distance and indexes of images associated\n",
        "d, i = index.search(image_features,5)"
      ],
      "metadata": {
        "id": "RShf2xfo1QoT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display images"
      ],
      "metadata": {
        "id": "YBSgxaI_9zry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use index number to get images from the image list\n",
        "retrieved_images = [images[idx] for idx in i[0]]\n",
        "\n",
        "# Set axes\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Display home image\n",
        "axes[0].imshow(mpimg.imread(HOME_IMAGE))\n",
        "axes[0].set_title('Home Image')\n",
        "axes[0].axis('off')\n",
        "\n",
        "# Display similar images\n",
        "for ax, img_path, distance in zip(axes[1:], retrieved_images, d[0]):\n",
        "    ax.imshow(mpimg.imread(img_path))\n",
        "    ax.set_title(f'Similarity: {distance:.2f}')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fn1pxMC19zX4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}